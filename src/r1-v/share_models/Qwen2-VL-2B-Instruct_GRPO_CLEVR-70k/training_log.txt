W0430 13:24:13.019000 605975 torch/distributed/run.py:792] 
W0430 13:24:13.019000 605975 torch/distributed/run.py:792] *****************************************
W0430 13:24:13.019000 605975 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0430 13:24:13.019000 605975 torch/distributed/run.py:792] *****************************************
[2025-04-30 13:24:32,473] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-30 13:24:32,473] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-30 13:24:32,473] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-30 13:24:32,473] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 04-30 13:24:39 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 04-30 13:24:39 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 04-30 13:24:39 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 04-30 13:24:39 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 04-30 13:24:39 [__init__.py:239] Automatically detected platform cuda.
INFO 04-30 13:24:39 [__init__.py:239] Automatically detected platform cuda.
INFO 04-30 13:24:39 [__init__.py:239] Automatically detected platform cuda.
INFO 04-30 13:24:39 [__init__.py:239] Automatically detected platform cuda.
usage: grpo.py [-h] --dataset_name DATASET_NAME
               [--dataset_config DATASET_CONFIG]
               [--dataset_train_split DATASET_TRAIN_SPLIT]
               [--dataset_test_split DATASET_TEST_SPLIT]
               [--gradient_checkpointing_use_reentrant [GRADIENT_CHECKPOINTING_USE_REENTRANT]]
               [--ignore_bias_buffers [IGNORE_BIAS_BUFFERS]]
               [--reward_funcs REWARD_FUNCS [REWARD_FUNCS ...]]
               [--max_pixels MAX_PIXELS] [--min_pixels MIN_PIXELS]
               [--output_dir OUTPUT_DIR]
               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
               [--do_predict [DO_PREDICT]] [--eval_strategy {no,steps,epoch}]
               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
               [--eval_delay EVAL_DELAY]
               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
               [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY]
               [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
               [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]
               [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]
               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
               [--warmup_ratio WARMUP_RATIO] [--warmup_steps WARMUP_STEPS]
               [--log_level {detail,debug,info,warning,error,critical,passive}]
               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
               [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node]
               [--logging_dir LOGGING_DIR]
               [--logging_strategy {no,steps,epoch}]
               [--logging_first_step [LOGGING_FIRST_STEP]]
               [--logging_steps LOGGING_STEPS]
               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
               [--no_logging_nan_inf_filter]
               [--save_strategy {no,steps,epoch,best}]
               [--save_steps SAVE_STEPS] [--save_total_limit SAVE_TOTAL_LIMIT]
               [--save_safetensors [SAVE_SAFETENSORS]] [--no_save_safetensors]
               [--save_on_each_node [SAVE_ON_EACH_NODE]]
               [--save_only_model [SAVE_ONLY_MODEL]]
               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
               [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]
               [--data_seed DATA_SEED] [--jit_mode_eval [JIT_MODE_EVAL]]
               [--use_ipex [USE_IPEX]] [--bf16 [BF16]] [--fp16 [FP16]]
               [--fp16_opt_level FP16_OPT_LEVEL]
               [--half_precision_backend {auto,apex,cpu_amp}]
               [--bf16_full_eval [BF16_FULL_EVAL]]
               [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]
               [--local_rank LOCAL_RANK]
               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
               [--tpu_num_cores TPU_NUM_CORES]
               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
               [--debug DEBUG [DEBUG ...]]
               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
               [--eval_steps EVAL_STEPS]
               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
               [--past_index PAST_INDEX] [--run_name RUN_NAME]
               [--disable_tqdm DISABLE_TQDM]
               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
               [--greater_is_better GREATER_IS_BETTER]
               [--ignore_data_skip [IGNORE_DATA_SKIP]] [--fsdp FSDP]
               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
               [--fsdp_config FSDP_CONFIG]
               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
               [--accelerator_config ACCELERATOR_CONFIG]
               [--deepspeed DEEPSPEED]
               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
               [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]
               [--group_by_length [GROUP_BY_LENGTH]]
               [--length_column_name LENGTH_COLUMN_NAME]
               [--report_to REPORT_TO]
               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
               [--no_dataloader_pin_memory]
               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
               [--no_skip_memory_metrics]
               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
               [--push_to_hub [PUSH_TO_HUB]]
               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
               [--hub_model_id HUB_MODEL_ID]
               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
               [--hub_token HUB_TOKEN] [--hub_private_repo HUB_PRIVATE_REPO]
               [--hub_always_push [HUB_ALWAYS_PUSH]]
               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
               [--no_eval_do_concat_batches]
               [--fp16_backend {auto,apex,cpu_amp}]
               [--evaluation_strategy {no,steps,epoch}]
               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
               [--mp_parameters MP_PARAMETERS]
               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
               [--full_determinism [FULL_DETERMINISM]]
               [--torchdynamo TORCHDYNAMO] [--ray_scope RAY_SCOPE]
               [--ddp_timeout DDP_TIMEOUT] [--torch_compile [TORCH_COMPILE]]
               [--torch_compile_backend TORCH_COMPILE_BACKEND]
               [--torch_compile_mode TORCH_COMPILE_MODE]
               [--dispatch_batches DISPATCH_BATCHES]
               [--split_batches SPLIT_BATCHES]
               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
               [--optim_target_modules OPTIM_TARGET_MODULES]
               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
               [--eval_on_start [EVAL_ON_START]]
               [--use_liger_kernel [USE_LIGER_KERNEL]]
               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
               [--model_init_kwargs MODEL_INIT_KWARGS]
               [--max_prompt_length MAX_PROMPT_LENGTH]
               [--num_generations NUM_GENERATIONS] [--temperature TEMPERATURE]
               [--max_completion_length MAX_COMPLETION_LENGTH]
               [--use_vllm [USE_VLLM]] [--vllm_device VLLM_DEVICE]
               [--vllm_gpu_memory_utilization VLLM_GPU_MEMORY_UTILIZATION]
               [--beta BETA] [--model_name_or_path MODEL_NAME_OR_PATH]
               [--model_revision MODEL_REVISION]
               [--torch_dtype {auto,bfloat16,float16,float32}]
               [--trust_remote_code [TRUST_REMOTE_CODE]]
               [--attn_implementation ATTN_IMPLEMENTATION]
               [--use_peft [USE_PEFT]] [--lora_r LORA_R]
               [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]
               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
               [--lora_task_type LORA_TASK_TYPE] [--use_rslora [USE_RSLORA]]
               [--load_in_8bit [LOAD_IN_8BIT]] [--load_in_4bit [LOAD_IN_4BIT]]
               [--bnb_4bit_quant_type {fp4,nf4}]
               [--use_bnb_nested_quant [USE_BNB_NESTED_QUANT]]
grpo.py: error: argument --model_name_or_path/--model-name-or-path: expected one argument
usage: grpo.py [-h] --dataset_name DATASET_NAME
               [--dataset_config DATASET_CONFIG]
               [--dataset_train_split DATASET_TRAIN_SPLIT]
               [--dataset_test_split DATASET_TEST_SPLIT]
               [--gradient_checkpointing_use_reentrant [GRADIENT_CHECKPOINTING_USE_REENTRANT]]
               [--ignore_bias_buffers [IGNORE_BIAS_BUFFERS]]
               [--reward_funcs REWARD_FUNCS [REWARD_FUNCS ...]]
               [--max_pixels MAX_PIXELS] [--min_pixels MIN_PIXELS]
               [--output_dir OUTPUT_DIR]
               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
               [--do_predict [DO_PREDICT]] [--eval_strategy {no,steps,epoch}]
               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
               [--eval_delay EVAL_DELAY]
               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
               [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY]
               [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
               [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]
               [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]
               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
               [--warmup_ratio WARMUP_RATIO] [--warmup_steps WARMUP_STEPS]
               [--log_level {detail,debug,info,warning,error,critical,passive}]
               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
               [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node]
               [--logging_dir LOGGING_DIR]
               [--logging_strategy {no,steps,epoch}]
               [--logging_first_step [LOGGING_FIRST_STEP]]
               [--logging_steps LOGGING_STEPS]
               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
               [--no_logging_nan_inf_filter]
               [--save_strategy {no,steps,epoch,best}]
               [--save_steps SAVE_STEPS] [--save_total_limit SAVE_TOTAL_LIMIT]
               [--save_safetensors [SAVE_SAFETENSORS]] [--no_save_safetensors]
               [--save_on_each_node [SAVE_ON_EACH_NODE]]
               [--save_only_model [SAVE_ONLY_MODEL]]
               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
               [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]
               [--data_seed DATA_SEED] [--jit_mode_eval [JIT_MODE_EVAL]]
               [--use_ipex [USE_IPEX]] [--bf16 [BF16]] [--fp16 [FP16]]
               [--fp16_opt_level FP16_OPT_LEVEL]
               [--half_precision_backend {auto,apex,cpu_amp}]
               [--bf16_full_eval [BF16_FULL_EVAL]]
               [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]
               [--local_rank LOCAL_RANK]
               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
               [--tpu_num_cores TPU_NUM_CORES]
               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
               [--debug DEBUG [DEBUG ...]]
               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
               [--eval_steps EVAL_STEPS]
               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
               [--past_index PAST_INDEX] [--run_name RUN_NAME]
               [--disable_tqdm DISABLE_TQDM]
               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
               [--greater_is_better GREATER_IS_BETTER]
               [--ignore_data_skip [IGNORE_DATA_SKIP]] [--fsdp FSDP]
               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
               [--fsdp_config FSDP_CONFIG]
               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
               [--accelerator_config ACCELERATOR_CONFIG]
               [--deepspeed DEEPSPEED]
               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
               [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]
               [--group_by_length [GROUP_BY_LENGTH]]
               [--length_column_name LENGTH_COLUMN_NAME]
               [--report_to REPORT_TO]
               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
               [--no_dataloader_pin_memory]
               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
               [--no_skip_memory_metrics]
               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
               [--push_to_hub [PUSH_TO_HUB]]
               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
               [--hub_model_id HUB_MODEL_ID]
               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
               [--hub_token HUB_TOKEN] [--hub_private_repo HUB_PRIVATE_REPO]
               [--hub_always_push [HUB_ALWAYS_PUSH]]
               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
               [--no_eval_do_concat_batches]
               [--fp16_backend {auto,apex,cpu_amp}]
               [--evaluation_strategy {no,steps,epoch}]
               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
               [--mp_parameters MP_PARAMETERS]
               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
               [--full_determinism [FULL_DETERMINISM]]
               [--torchdynamo TORCHDYNAMO] [--ray_scope RAY_SCOPE]
               [--ddp_timeout DDP_TIMEOUT] [--torch_compile [TORCH_COMPILE]]
               [--torch_compile_backend TORCH_COMPILE_BACKEND]
               [--torch_compile_mode TORCH_COMPILE_MODE]
               [--dispatch_batches DISPATCH_BATCHES]
               [--split_batches SPLIT_BATCHES]
               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
               [--optim_target_modules OPTIM_TARGET_MODULES]
               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
               [--eval_on_start [EVAL_ON_START]]
               [--use_liger_kernel [USE_LIGER_KERNEL]]
               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
               [--model_init_kwargs MODEL_INIT_KWARGS]
               [--max_prompt_length MAX_PROMPT_LENGTH]
               [--num_generations NUM_GENERATIONS] [--temperature TEMPERATURE]
               [--max_completion_length MAX_COMPLETION_LENGTH]
               [--use_vllm [USE_VLLM]] [--vllm_device VLLM_DEVICE]
               [--vllm_gpu_memory_utilization VLLM_GPU_MEMORY_UTILIZATION]
               [--beta BETA] [--model_name_or_path MODEL_NAME_OR_PATH]
               [--model_revision MODEL_REVISION]
               [--torch_dtype {auto,bfloat16,float16,float32}]
               [--trust_remote_code [TRUST_REMOTE_CODE]]
               [--attn_implementation ATTN_IMPLEMENTATION]
               [--use_peft [USE_PEFT]] [--lora_r LORA_R]
               [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]
               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
               [--lora_task_type LORA_TASK_TYPE] [--use_rslora [USE_RSLORA]]
               [--load_in_8bit [LOAD_IN_8BIT]] [--load_in_4bit [LOAD_IN_4BIT]]
               [--bnb_4bit_quant_type {fp4,nf4}]
               [--use_bnb_nested_quant [USE_BNB_NESTED_QUANT]]
grpo.py: error: argument --model_name_or_path/--model-name-or-path: expected one argument
usage: grpo.py [-h] --dataset_name DATASET_NAME
               [--dataset_config DATASET_CONFIG]
               [--dataset_train_split DATASET_TRAIN_SPLIT]
               [--dataset_test_split DATASET_TEST_SPLIT]
               [--gradient_checkpointing_use_reentrant [GRADIENT_CHECKPOINTING_USE_REENTRANT]]
               [--ignore_bias_buffers [IGNORE_BIAS_BUFFERS]]
               [--reward_funcs REWARD_FUNCS [REWARD_FUNCS ...]]
               [--max_pixels MAX_PIXELS] [--min_pixels MIN_PIXELS]
               [--output_dir OUTPUT_DIR]
               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
               [--do_predict [DO_PREDICT]] [--eval_strategy {no,steps,epoch}]
               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
               [--eval_delay EVAL_DELAY]
               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
               [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY]
               [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
               [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]
               [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]
               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
               [--warmup_ratio WARMUP_RATIO] [--warmup_steps WARMUP_STEPS]
               [--log_level {detail,debug,info,warning,error,critical,passive}]
               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
               [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node]
               [--logging_dir LOGGING_DIR]
               [--logging_strategy {no,steps,epoch}]
               [--logging_first_step [LOGGING_FIRST_STEP]]
               [--logging_steps LOGGING_STEPS]
               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
               [--no_logging_nan_inf_filter]
               [--save_strategy {no,steps,epoch,best}]
               [--save_steps SAVE_STEPS] [--save_total_limit SAVE_TOTAL_LIMIT]
               [--save_safetensors [SAVE_SAFETENSORS]] [--no_save_safetensors]
               [--save_on_each_node [SAVE_ON_EACH_NODE]]
               [--save_only_model [SAVE_ONLY_MODEL]]
               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
               [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]
               [--data_seed DATA_SEED] [--jit_mode_eval [JIT_MODE_EVAL]]
               [--use_ipex [USE_IPEX]] [--bf16 [BF16]] [--fp16 [FP16]]
               [--fp16_opt_level FP16_OPT_LEVEL]
               [--half_precision_backend {auto,apex,cpu_amp}]
               [--bf16_full_eval [BF16_FULL_EVAL]]
               [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]
               [--local_rank LOCAL_RANK]
               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
               [--tpu_num_cores TPU_NUM_CORES]
               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
               [--debug DEBUG [DEBUG ...]]
               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
               [--eval_steps EVAL_STEPS]
               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
               [--past_index PAST_INDEX] [--run_name RUN_NAME]
               [--disable_tqdm DISABLE_TQDM]
               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
               [--greater_is_better GREATER_IS_BETTER]
               [--ignore_data_skip [IGNORE_DATA_SKIP]] [--fsdp FSDP]
               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
               [--fsdp_config FSDP_CONFIG]
               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
               [--accelerator_config ACCELERATOR_CONFIG]
               [--deepspeed DEEPSPEED]
               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
               [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]
               [--group_by_length [GROUP_BY_LENGTH]]
               [--length_column_name LENGTH_COLUMN_NAME]
               [--report_to REPORT_TO]
               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
               [--no_dataloader_pin_memory]
               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
               [--no_skip_memory_metrics]
               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
               [--push_to_hub [PUSH_TO_HUB]]
               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
               [--hub_model_id HUB_MODEL_ID]
               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
               [--hub_token HUB_TOKEN] [--hub_private_repo HUB_PRIVATE_REPO]
               [--hub_always_push [HUB_ALWAYS_PUSH]]
               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
               [--no_eval_do_concat_batches]
               [--fp16_backend {auto,apex,cpu_amp}]
               [--evaluation_strategy {no,steps,epoch}]
               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
               [--mp_parameters MP_PARAMETERS]
               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
               [--full_determinism [FULL_DETERMINISM]]
               [--torchdynamo TORCHDYNAMO] [--ray_scope RAY_SCOPE]
               [--ddp_timeout DDP_TIMEOUT] [--torch_compile [TORCH_COMPILE]]
               [--torch_compile_backend TORCH_COMPILE_BACKEND]
               [--torch_compile_mode TORCH_COMPILE_MODE]
               [--dispatch_batches DISPATCH_BATCHES]
               [--split_batches SPLIT_BATCHES]
               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
               [--optim_target_modules OPTIM_TARGET_MODULES]
               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
               [--eval_on_start [EVAL_ON_START]]
               [--use_liger_kernel [USE_LIGER_KERNEL]]
               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
               [--model_init_kwargs MODEL_INIT_KWARGS]
               [--max_prompt_length MAX_PROMPT_LENGTH]
               [--num_generations NUM_GENERATIONS] [--temperature TEMPERATURE]
               [--max_completion_length MAX_COMPLETION_LENGTH]
               [--use_vllm [USE_VLLM]] [--vllm_device VLLM_DEVICE]
               [--vllm_gpu_memory_utilization VLLM_GPU_MEMORY_UTILIZATION]
               [--beta BETA] [--model_name_or_path MODEL_NAME_OR_PATH]
               [--model_revision MODEL_REVISION]
               [--torch_dtype {auto,bfloat16,float16,float32}]
               [--trust_remote_code [TRUST_REMOTE_CODE]]
               [--attn_implementation ATTN_IMPLEMENTATION]
               [--use_peft [USE_PEFT]] [--lora_r LORA_R]
               [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]
               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
               [--lora_task_type LORA_TASK_TYPE] [--use_rslora [USE_RSLORA]]
               [--load_in_8bit [LOAD_IN_8BIT]] [--load_in_4bit [LOAD_IN_4BIT]]
               [--bnb_4bit_quant_type {fp4,nf4}]
               [--use_bnb_nested_quant [USE_BNB_NESTED_QUANT]]
grpo.py: error: argument --model_name_or_path/--model-name-or-path: expected one argument
usage: grpo.py [-h] --dataset_name DATASET_NAME
               [--dataset_config DATASET_CONFIG]
               [--dataset_train_split DATASET_TRAIN_SPLIT]
               [--dataset_test_split DATASET_TEST_SPLIT]
               [--gradient_checkpointing_use_reentrant [GRADIENT_CHECKPOINTING_USE_REENTRANT]]
               [--ignore_bias_buffers [IGNORE_BIAS_BUFFERS]]
               [--reward_funcs REWARD_FUNCS [REWARD_FUNCS ...]]
               [--max_pixels MAX_PIXELS] [--min_pixels MIN_PIXELS]
               [--output_dir OUTPUT_DIR]
               [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
               [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
               [--do_predict [DO_PREDICT]] [--eval_strategy {no,steps,epoch}]
               [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
               [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
               [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
               [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
               [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
               [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
               [--eval_delay EVAL_DELAY]
               [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]
               [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY]
               [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
               [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]
               [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]
               [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]
               [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]
               [--warmup_ratio WARMUP_RATIO] [--warmup_steps WARMUP_STEPS]
               [--log_level {detail,debug,info,warning,error,critical,passive}]
               [--log_level_replica {detail,debug,info,warning,error,critical,passive}]
               [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node]
               [--logging_dir LOGGING_DIR]
               [--logging_strategy {no,steps,epoch}]
               [--logging_first_step [LOGGING_FIRST_STEP]]
               [--logging_steps LOGGING_STEPS]
               [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]
               [--no_logging_nan_inf_filter]
               [--save_strategy {no,steps,epoch,best}]
               [--save_steps SAVE_STEPS] [--save_total_limit SAVE_TOTAL_LIMIT]
               [--save_safetensors [SAVE_SAFETENSORS]] [--no_save_safetensors]
               [--save_on_each_node [SAVE_ON_EACH_NODE]]
               [--save_only_model [SAVE_ONLY_MODEL]]
               [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]
               [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]
               [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]
               [--data_seed DATA_SEED] [--jit_mode_eval [JIT_MODE_EVAL]]
               [--use_ipex [USE_IPEX]] [--bf16 [BF16]] [--fp16 [FP16]]
               [--fp16_opt_level FP16_OPT_LEVEL]
               [--half_precision_backend {auto,apex,cpu_amp}]
               [--bf16_full_eval [BF16_FULL_EVAL]]
               [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]
               [--local_rank LOCAL_RANK]
               [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]
               [--tpu_num_cores TPU_NUM_CORES]
               [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
               [--debug DEBUG [DEBUG ...]]
               [--dataloader_drop_last [DATALOADER_DROP_LAST]]
               [--eval_steps EVAL_STEPS]
               [--dataloader_num_workers DATALOADER_NUM_WORKERS]
               [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]
               [--past_index PAST_INDEX] [--run_name RUN_NAME]
               [--disable_tqdm DISABLE_TQDM]
               [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
               [--label_names LABEL_NAMES [LABEL_NAMES ...]]
               [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
               [--metric_for_best_model METRIC_FOR_BEST_MODEL]
               [--greater_is_better GREATER_IS_BETTER]
               [--ignore_data_skip [IGNORE_DATA_SKIP]] [--fsdp FSDP]
               [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
               [--fsdp_config FSDP_CONFIG]
               [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
               [--accelerator_config ACCELERATOR_CONFIG]
               [--deepspeed DEEPSPEED]
               [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
               [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]
               [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]
               [--group_by_length [GROUP_BY_LENGTH]]
               [--length_column_name LENGTH_COLUMN_NAME]
               [--report_to REPORT_TO]
               [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
               [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]
               [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]
               [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
               [--no_dataloader_pin_memory]
               [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]
               [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
               [--no_skip_memory_metrics]
               [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
               [--push_to_hub [PUSH_TO_HUB]]
               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
               [--hub_model_id HUB_MODEL_ID]
               [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]
               [--hub_token HUB_TOKEN] [--hub_private_repo HUB_PRIVATE_REPO]
               [--hub_always_push [HUB_ALWAYS_PUSH]]
               [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
               [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]
               [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]
               [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]
               [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]
               [--no_eval_do_concat_batches]
               [--fp16_backend {auto,apex,cpu_amp}]
               [--evaluation_strategy {no,steps,epoch}]
               [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
               [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
               [--push_to_hub_token PUSH_TO_HUB_TOKEN]
               [--mp_parameters MP_PARAMETERS]
               [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]
               [--full_determinism [FULL_DETERMINISM]]
               [--torchdynamo TORCHDYNAMO] [--ray_scope RAY_SCOPE]
               [--ddp_timeout DDP_TIMEOUT] [--torch_compile [TORCH_COMPILE]]
               [--torch_compile_backend TORCH_COMPILE_BACKEND]
               [--torch_compile_mode TORCH_COMPILE_MODE]
               [--dispatch_batches DISPATCH_BATCHES]
               [--split_batches SPLIT_BATCHES]
               [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]
               [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]
               [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]
               [--optim_target_modules OPTIM_TARGET_MODULES]
               [--batch_eval_metrics [BATCH_EVAL_METRICS]]
               [--eval_on_start [EVAL_ON_START]]
               [--use_liger_kernel [USE_LIGER_KERNEL]]
               [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]
               [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]
               [--model_init_kwargs MODEL_INIT_KWARGS]
               [--max_prompt_length MAX_PROMPT_LENGTH]
               [--num_generations NUM_GENERATIONS] [--temperature TEMPERATURE]
               [--max_completion_length MAX_COMPLETION_LENGTH]
               [--use_vllm [USE_VLLM]] [--vllm_device VLLM_DEVICE]
               [--vllm_gpu_memory_utilization VLLM_GPU_MEMORY_UTILIZATION]
               [--beta BETA] [--model_name_or_path MODEL_NAME_OR_PATH]
               [--model_revision MODEL_REVISION]
               [--torch_dtype {auto,bfloat16,float16,float32}]
               [--trust_remote_code [TRUST_REMOTE_CODE]]
               [--attn_implementation ATTN_IMPLEMENTATION]
               [--use_peft [USE_PEFT]] [--lora_r LORA_R]
               [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]
               [--lora_target_modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
               [--lora_modules_to_save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
               [--lora_task_type LORA_TASK_TYPE] [--use_rslora [USE_RSLORA]]
               [--load_in_8bit [LOAD_IN_8BIT]] [--load_in_4bit [LOAD_IN_4BIT]]
               [--bnb_4bit_quant_type {fp4,nf4}]
               [--use_bnb_nested_quant [USE_BNB_NESTED_QUANT]]
grpo.py: error: argument --model_name_or_path/--model-name-or-path: expected one argument
W0430 13:24:47.654000 605975 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 606041 closing signal SIGTERM
W0430 13:24:47.655000 605975 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 606042 closing signal SIGTERM
W0430 13:24:47.656000 605975 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 606044 closing signal SIGTERM
E0430 13:24:47.870000 605975 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 2 (pid: 606043) of binary: /gpfs/home6/rritter/test/R1-V/.venv/bin/python3
Traceback (most recent call last):
  File "/gpfs/home6/rritter/test/R1-V/.venv/bin/torchrun", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/gpfs/home6/rritter/test/R1-V/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/rritter/test/R1-V/.venv/lib/python3.12/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/gpfs/home6/rritter/test/R1-V/.venv/lib/python3.12/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/gpfs/home6/rritter/test/R1-V/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/rritter/test/R1-V/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/open_r1/grpo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-04-30_13:24:47
  host      : gcn158.local.snellius.surf.nl
  rank      : 2 (local_rank: 2)
  exitcode  : 2 (pid: 606043)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
